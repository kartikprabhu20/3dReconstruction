\babel@toc {english}{}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces A graph showing how synthetic dataset will evolve overtime. The research graph shows that synthetic dataset will overshadow the existing real dataset\textsuperscript {\ref {gartnerreport}}. Source: Research article from Gartner on "Synthetic Data Is the Future of AI"\textsuperscript {\ref {gartnerreport}}\relax }}{2}{figure.caption.8}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces 3D representation of Standford bunny model.(left to right) Point cloud, voxel and mesh~\cite {Hoang2019ADL} \relax }}{4}{figure.caption.9}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Network architectures used as a baselines (a)Pix2Vox~\cite {Xie_2019} (b)Pix2Vox++~\cite {Xie_2020}. The critical difference between the two architectures is the Encoder. Pix2Vox uses \gls {vgg} while Pix2Vox++ uses \gls {resnet}.\relax }}{10}{figure.caption.10}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Sample RGB images from pix3D\relax }}{11}{figure.caption.11}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces A collection of photorealistic synthetic datasets. The first column of each row indicates the dataset name followed by randomly selected images from the same dataset.\relax }}{14}{figure.caption.13}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Sample images created from BlenderProc using SceneNet dataset.(Left to right) RGB images, Depth Maps, Instance Segmenatations and Normals. Each row is an independent sample.\relax }}{15}{figure.caption.14}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Distribution of Pix3D~\cite {Sun2018} images(left), unique models(right)\relax }}{22}{figure.caption.15}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces An overview of pipeline for image generation with different blocks and external libraries.\relax }}{24}{figure.caption.16}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces (Left)Distribution of types of scenes, (Right) Distribution of objects matching the categories of Pix3D in scenes. The chair category has most number of possible positions, while wardrobe has the least.\relax }}{24}{figure.caption.17}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces The top view of sample scene layouts from SceneNet. Types: (a)Bedroom, (b)LivingRoom, (c)Kitchen and (d)Office\relax }}{25}{figure.caption.18}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Sample images with different textures for same scene.\relax }}{26}{figure.caption.19}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Distribution of textures used on scenes. The categories of Pix3D(target furniture) have higher number of images.\relax }}{26}{figure.caption.20}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Samples for different skyboxes which change the outdoor environment for the scenes. In the figure we see an open window with changing skybox.\relax }}{27}{figure.caption.21}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Samples for object replacement. The Left column shows a scene from SceneNet, while the right column shows an object being replaced in original scene.\relax }}{28}{figure.caption.22}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Sample images with different camera viewpoints of same object with a constant scene.\relax }}{28}{figure.caption.23}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Sample images with different lighting and shadows conditions.First row is samples for light with different intensity and direction. Second row is differnt color for light.\relax }}{29}{figure.caption.24}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces A survey conducted by~\cite {Han2021ImageBased3O}, demonstrates that Pix2Vox is considerably a good 3D reconstruction model. The values are from 3D reconstruction of ShapeNet~\cite {shapenet2015} since Pix3D was not published by then.\relax }}{30}{figure.caption.25}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces Samples of images from real and synthetic datasets.\relax }}{31}{figure.caption.26}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces Samples of images used for ablation study on chairs with different parameters of domain randomization.\relax }}{32}{figure.caption.27}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Flowchart for the 3D-Scene Pipeline. The pipeline iterates through the steps till a specified count is reached.\relax }}{36}{figure.caption.28}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Samples for G-buffers collected from ImageSynthesis as part of the dataset. In the figure, (From left to right) RGB image, Depth map, Instance segmentation, Semantic Segmentation and Normal map\relax }}{41}{figure.caption.29}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces A screenshot of the Unity based application developed for proof of concept to create synthetic dataset.\relax }}{42}{figure.caption.30}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces A screenshot of the Unity based application in action, the user is able to configure the pipeline using GUI and take snapshots either automatically or manually.\relax }}{42}{figure.caption.31}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces The figure represents distribution for Section 1 of survey. The participants were asked to distinguish if the image was 'Real' or 'Nor Real'. The automated dataset is highlighted with bolder color. The dotted line is 50\% threshold. All the automated dataset have less than threshold votes for 'Real'.\relax }}{47}{figure.caption.33}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces The figure represents distribution for Section 2 of survey. The participants were asked to rate the image based on photorealism(1 being the least photorealistic). \gls {free} has maximum number of least rating(1), but it is comparable to other automated datasets as highlighted. Pix3D has maximum number of highest rating(10).\relax }}{48}{figure.caption.34}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces The figure represents average rating given by the participant to each of the datasets in section 2 of the survey. The automated datasets are highlighted, all of them have lower average. \gls {ai2thor}(Unity based and manually designed) is also among the lower averages.\relax }}{48}{figure.caption.35}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces The figure represents distribution for Section 3 of survey. The participants were asked to rank the images based on photorealism(1 being the best) by comparing images from all 9 datasets. The automated datasets are highlighted. \gls {free} dataset appears in top 5 maximum number of times, seen to the left of the dotted line.\relax }}{49}{figure.caption.36}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces The figure represents box plot for section 3. The orange horizontal line within the box indicates median, the blue dotted line indicates mean. The bolder boxes represents automated dataset, while lighter boxes represent manually created dataset. \Gls {free} has highest mean among the automated datasets.\relax }}{49}{figure.caption.37}%
\contentsline {figure}{\numberline {5.6}{\ignorespaces \gls {tsne} visualization for images from various photo-realistic synthetic dataset. Pix3D and \gls {free} are highlighted with bolder colors. Both these datasets have wide spread in the embedding space.\relax }}{50}{figure.caption.38}%
\contentsline {figure}{\numberline {5.7}{\ignorespaces \gls {tsne} visualization for images from individual photo-realistic synthetic dataset compared with Pix3D latent space. (Left to right, top to bottom) Openrooms, SceneNet, Blenderproc, \gls {ai2thor}, \gls {front}, Hyperism, InteriorNet, \gls {free} in blue; compared with Pix3D in orange.\relax }}{51}{figure.caption.39}%
\contentsline {figure}{\numberline {5.8}{\ignorespaces \gls {tsne} visualization for images from Pix3D and \gls {free} dataset.We observe that \gls {free} still doesnt encapsulate the embedding space like Pix3D.\relax }}{52}{figure.caption.40}%
\contentsline {figure}{\numberline {5.9}{\ignorespaces \gls {tsne} visualization for images from individual synthetic chair dataset with different domain randomization parameter compared with Pix3D chair latent space. (Left to right, top to bottom) Textureless, Textureless with light, Textured, Textured with light, Multi-Object and Combined.\relax }}{54}{figure.caption.42}%
\contentsline {figure}{\numberline {5.10}{\ignorespaces Bar plot for the \gls {iou} for \textbf {baselines} trained on real and synthetic datasets, with and without 2D augmentation. (a)The checkpoint was saved using real dataset for validation and test, (b) The checkpoint was saved using corresponding synthetic data for validation step and tested with real data. In both the cases we see that ~\gls {free} does not perform adequately on its own. \gls {s2rv2} contributes better than \gls {s2rv1}.\relax }}{56}{figure.caption.44}%
\contentsline {figure}{\numberline {5.11}{\ignorespaces 3D reconstruction outputs for models trained on \textbf {only real dataset}, and \textbf {only synthetic dataset}. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D(real dataset). Output3-4: Pix2Vox++ and Pix2Vox trained with only \gls {s2rv2} synthetic dataset. This corresponds to the bad \gls {iou} when trained on only synthetic dataset.\relax }}{57}{figure.caption.45}%
\contentsline {figure}{\numberline {5.12}{\ignorespaces Bar plot for the \gls {iou} for baseline models(Pix2Vox++ and Pix2Vox) trained on synthetic and \textbf {fine-tuned} with real dataset. We see that even after fine-tuning both the models do not perform as good as models trained on only real dataset.\relax }}{58}{figure.caption.46}%
\contentsline {figure}{\numberline {5.13}{\ignorespaces Bar plot for the \gls {iou} for baseline {Pix2Vox++} trained on (\gls {s2rv1}, \gls {s2rv2}) and \textbf {fine-tuned} with Pix3D. The categories are listed along with the number of images. The performance of {Pix2Vox++} mixed with both the synthetic dataset is less than model trained on only Pix3D, for majority of the categories.\relax }}{59}{figure.caption.47}%
\contentsline {figure}{\numberline {5.14}{\ignorespaces Bar plot for the \gls {iou} for baseline {Pix2Vox} trained on (\gls {s2rv1}, \gls {s2rv2}) and {fine-tuned} with Pix3D. The categories are listed along with the number of images. The performance of \textbf {Pix2Vox} mixed with both the synthetic dataset is less than model trained on only Pix3D, for majority the categories.\relax }}{59}{figure.caption.48}%
\contentsline {figure}{\numberline {5.15}{\ignorespaces 3D reconstruction outputs for models trained on real dataset and synthetic datasets with \textbf {fine-tuning}. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D(real dataset). Output3-4: Pix2Vox++ and Pix2Vox pre-trained with only \gls {s2rv2} synthetic dataset and then fine-tuned with Pix3D. The reconstruction is better than models trained on only synthetic dataset.\relax }}{60}{figure.caption.49}%
\contentsline {figure}{\numberline {5.16}{\ignorespaces Bar plot for the \gls {iou} for baselines trained on different ratios of synthetic and real dataset per mini-batch.(a)\textbf {Mixed training on Pix2Vox++}, (b)\textbf {Mixed training on Pix2Vox}. In both cases we see a slight increase in \gls {iou} with addition of real data, and a gradual decrease till it reaches 100\% real data\relax }}{61}{figure.caption.50}%
\contentsline {figure}{\numberline {5.17}{\ignorespaces Bar plot for the \gls {iou} for baseline {Pix2Vox++} trained on 50\% of \textbf {mixed dataset}(\gls {s2rv1}, \gls {s2rv2}) and with Pix3D. The categories are listed along with the number of images. The performance of Pix2Vox++ mixed with both the synthetic dataset is more than model trained on only Pix3D, for majority of the categories. \relax }}{62}{figure.caption.51}%
\contentsline {figure}{\numberline {5.18}{\ignorespaces Bar plot for the \gls {iou} for baseline {Pix2Vox} trained on 50\% of \textbf {mixed dataset}(\gls {s2rv1}, \gls {s2rv2}) and with Pix3D. The categories are listed along with the number of images. The performance of Pix2Vox mixed with both the synthetic dataset is more than model trained on only Pix3D, for all the categories.\relax }}{62}{figure.caption.52}%
\contentsline {figure}{\numberline {5.19}{\ignorespaces 3D reconstruction outputs for best \textbf {mixed training}(50\% per mini-batch) models. Output1-2: Pix2Vox++ and Pix2Vox mixed trained with \gls {s2rv1}. Output3-4:Pix2Vox++ and Pix2Vox mixed trained with \gls {s2rv2}\relax }}{63}{figure.caption.53}%
\contentsline {figure}{\numberline {5.20}{\ignorespaces Bar plot for the \gls {iou} for \textbf {baseline} trained on chair dataset with different domain randomization parameters and tested on real dataset. We see a dip in performance near textureless dataset, but it gradually increases with addition of domain randomization parameter.\relax }}{64}{figure.caption.54}%
\contentsline {figure}{\numberline {5.21}{\ignorespaces 3D reconstruction outputs for best \textbf {ablation} models and models trained on only synthetic dataset. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D. Output3-4: Pix2Vox++ and Pix2Vox trained on Multi-object chair synthetic dataset, reconstructs a generic chair with less detail.\relax }}{66}{figure.caption.55}%
\contentsline {figure}{\numberline {5.22}{\ignorespaces Bar plot for the \gls {iou} for baseline trained by \textbf {mixing} chair dataset from real and synthetic dataset with ratio of 50\%. Observe that the {IoU} is consistent for all types of randomization proving that mixed training negates loss from randomization.]\relax }}{67}{figure.caption.56}%
\contentsline {figure}{\numberline {5.23}{\ignorespaces 3D reconstruction outputs for best ablation models and models with \textbf {mixed} training. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D. Output3-4:Pix2Vox++ and Pix2Vox trained with mixed ratio of 50\% with multi-object chair synthetic dataset, reconstructs chair with more details.\relax }}{68}{figure.caption.57}%
\contentsline {figure}{\numberline {5.24}{\ignorespaces A sample output where more than one furniture seem to be predicted. (left) Input image, (center) Ground truth, (right) Predicted output. The model seems to predict both the chair and the table with the context it learnt during training.\relax }}{69}{figure.caption.58}%
\contentsline {figure}{\numberline {5.25}{\ignorespaces A sample output where a more focused furniture is getting predicted instead of ground truth. (left) Input image, (center) Ground truth, (right) Predicted output. The model seems to predict the chair instead of the table. \relax }}{69}{figure.caption.59}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {A.1}{\ignorespaces Bar plot for the \gls {f1} for baselines trained on real and synthetic datasets, with and without 2D augmentation. We see that ~\gls {free} does not perform adequately on its own. \gls {s2rv2} contributes slightly better than \gls {s2rv1}.\relax }}{75}{figure.caption.61}%
\contentsline {figure}{\numberline {A.2}{\ignorespaces Bar plot for the \gls {f1} for baseline models(Pix2Vox++ and Pix2Vox) trained on synthetic and fine-tuned with real dataset. We see that even after fine-tuning both the models do not perform as good as models trained on only real dataset.\relax }}{76}{figure.caption.62}%
\contentsline {figure}{\numberline {A.3}{\ignorespaces Bar plot for the \gls {f1} for baseline pix2vox++ trained on (\gls {s2rv1}, \gls {s2rv2}) and fine-tuned with pix3d. The categories are listed along with the number of images. The performance of {pix2vox++} mixed with both the synthetic dataset is less than model trained on only pix3d, for majority of the categories.\relax }}{77}{figure.caption.63}%
\contentsline {figure}{\numberline {A.4}{\ignorespaces Bar plot for the \gls {f1} for baseline {pix2vox} trained on (\gls {s2rv1}, \gls {s2rv2}) and fine-tuned with pix3d. The categories are listed along with the number of images. The performance of pix2vox mixed with both the synthetic dataset is less than model trained on only pix3d, for majority the categories.\relax }}{78}{figure.caption.64}%
\contentsline {figure}{\numberline {A.5}{\ignorespaces Bar plot for the \gls {f1} for baselines trained on different ratios of synthetic and real dataset. (left)Mixed training on Pix2Vox++, (right)Mixed training on Pix2Vox. In both cases we see a slight increase in \gls {f1} with addition of real data, and a gradual decrease till it reaches 100\% real data\relax }}{78}{figure.caption.65}%
\contentsline {figure}{\numberline {A.6}{\ignorespaces Bar plot for the \gls {f1} for baseline {pix2vox++} trained on 50\% of mixed dataset(\gls {s2rv1}, \gls {s2rv2}) and with pix3d. The categories are listed along with the number of images. The performance of pix2vox++ mixed with both the synthetic dataset is more than model trained on only pix3d, for most of the categories. \relax }}{79}{figure.caption.66}%
\contentsline {figure}{\numberline {A.7}{\ignorespaces Bar plot for the \gls {f1} for baseline {pix2vox} trained on 50\% of mixed dataset(\gls {s2rv1}, \gls {s2rv2}) and with pix3d. The categories are listed along with the number of images. The performance of pix2vox mixed with both the synthetic dataset is more than model trained on only pix3d, for all the categories.\relax }}{79}{figure.caption.67}%
\contentsline {figure}{\numberline {A.8}{\ignorespaces Bar plot for the \gls {f1} for baseline trained on chair dataset with different domain randomization parameters and tested on real dataset. We see a dip in performance near textureless dataset, but it gradually increases with addition of domain randomization parameter.\relax }}{80}{figure.caption.68}%
\contentsline {figure}{\numberline {A.9}{\ignorespaces Bar plot for the \gls {f1} for baseline trained by mixing chair dataset from real and synthetic dataset with ratio of 50\%. Observe that the {IoU} is consistent for all types of randomization proving that mixed training negates loss from randomization.\relax }}{81}{figure.caption.69}%
\contentsline {figure}{\numberline {A.10}{\ignorespaces 3D reconstruction outputs for models trained on \textbf {only real dataset}, and \textbf {only synthetic dataset}. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D(real dataset). Output3-4: Pix2Vox++ and Pix2Vox trained with only \gls {s2rv2} synthetic dataset. This corresponds to the bad \gls {iou} when trained on only synthetic dataset.\relax }}{82}{figure.caption.70}%
\contentsline {figure}{\numberline {A.11}{\ignorespaces 3D reconstruction outputs for models trained on real dataset and synthetic datasets with \textbf {fine-tuning}. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D(real dataset). Output3-4: Pix2Vox++ and Pix2Vox pre-trained with only \gls {s2rv2} synthetic dataset and then fine-tuned with Pix3d. The reconstruction is better than models trained on only synthetic dataset.\relax }}{83}{figure.caption.71}%
\contentsline {figure}{\numberline {A.12}{\ignorespaces 3D reconstruction outputs for best \textbf {mixed training}(50\% per mini-batch) models. Output1-2: Pix2Vox++ and Pix2Vox mixed trained with \gls {s2rv1}. Output3-4:Pix2Vox++ and Pix2Vox mixed trained with \gls {s2rv2}\relax }}{84}{figure.caption.72}%
\contentsline {figure}{\numberline {A.13}{\ignorespaces Sample images for models rendered in High Definition Render Pipeline of Unity\relax }}{85}{figure.caption.73}%
\contentsline {figure}{\numberline {A.14}{\ignorespaces 3D reconstruction outputs for best \textbf {mixed training}(50\% per mini-batch) models for empty rooms. We do not see a detailed reconstruction, but some of them resemble furniture category.\relax }}{86}{figure.caption.74}%
\contentsline {figure}{\numberline {A.15}{\ignorespaces A sample question used for survey section 1. For section 1, participants were asked to select 'Real' or 'Not real' for 27 images, 3 images per dataset.\relax }}{87}{figure.caption.75}%
\contentsline {figure}{\numberline {A.16}{\ignorespaces A sample question used for survey section 2. For section 2, participants were asked rate the 27 images from 1 to 10. We had 3 images per dataset.\relax }}{88}{figure.caption.76}%
\contentsline {figure}{\numberline {A.17}{\ignorespaces A sample question used for survey section 3. For section 3, the users were shown 9 images together and asked to rank them on descending order of photorealism. \relax }}{89}{figure.caption.77}%
