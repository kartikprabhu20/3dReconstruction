\babel@toc {english}{}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces A graph showing how synthetic dataset will evolve overtime. The research graph shows that synthetic dataset will overshadow the existing real dataset~\cite {gartnerreport}. Source: Research article from Gartner on "Synthetic Data Is the Future of AI"~\cite {gartnerreport}\relax }}{2}{figure.caption.11}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces 3D representation of Standford bunny model.(left to right) Point cloud, voxel and mesh~\cite {Hoang2019ADL} \relax }}{4}{figure.caption.12}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces A collection of photorealistic synthetic datasets. The first column of each row indicates the dataset name followed by randomly selected images from the same dataset.\relax }}{10}{figure.caption.13}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Sample images created from BlenderProc using SceneNet dataset.(Left to right) RGB images, Depth Maps, Instance Segmenatations and Normals. Each row is an independent sample.\relax }}{11}{figure.caption.14}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Distribution of pix3D~\cite {pix3d} images(left), unique models(right)\relax }}{16}{figure.caption.15}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Sample RGB images from pix3D\relax }}{17}{figure.caption.16}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Network architecture for pix2vox~\cite {Xie_2019}\relax }}{21}{figure.caption.17}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Network architecture for pix2vox++~\cite {Xie_2020}\relax }}{21}{figure.caption.18}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces A survey conducted by~\cite {Han2021ImageBased3O}, proves that Pix2Vox is considerably a good 3D reconstruction model. {\color {red} \emph {replace this figure with better one}}\relax }}{21}{figure.caption.19}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Automated pipeline for image generation with different blocks and external libraries.\relax }}{26}{figure.caption.20}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces The top view of sample scene layouts from SceneNet. Types: (a)Bedroom, (b)LivingRoom, (c)Kitchen and (d)Office\relax }}{27}{figure.caption.21}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces (Left)Distribution of types of scenes, (Right) Distribution of objects matching the categories of pix3d in scenes\relax }}{27}{figure.caption.22}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Sample images with different camera viewpoints of same object with a constant scene.\relax }}{28}{figure.caption.23}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Sample images with different lighting and shadows conditions.First row is samples for light with different intensity and direction. Second row is differnt color for light.\relax }}{29}{figure.caption.24}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Sample images with different textures for same scene.\relax }}{30}{figure.caption.25}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Distribution of textures used on scenes. The categories of pix3d(target furniture) have higher number of images.\relax }}{31}{figure.caption.26}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Samples for different skyboxes which change the outdoor environment for the scenes. In the figure we see an open window with changing skybox.\relax }}{32}{figure.caption.27}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces Samples for object replacement. The Left column shows a scene from SceneNet, while the right column shows an object being replaced in original scene.\relax }}{32}{figure.caption.28}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces Samples for G-buffers collected from ImageSynthesis as part of the dataset. In the figure, (From left to right) RGB image, Depth map, Instance segmentation, Semantic Segmentation and Normal map\relax }}{33}{figure.caption.29}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces A screenshot of the Unity based application developed for proof of concept to create synthetic dataset.\relax }}{34}{figure.caption.30}%
\contentsline {figure}{\numberline {4.12}{\ignorespaces A screenshot of the Unity based application in action, the user is able to configure the pipeline using GUI and take snapshots either automatically or manually.\relax }}{34}{figure.caption.31}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces The figure represents distribution for Section 1 of survey. The participants were asked to distinguish if the image was 'Real' or 'Nor Real'. The automated dataset is highlighted with bolder color. The dotted line is 50\% threshold. All the automated dataset have less than threshold votes for 'Real'.\relax }}{39}{figure.caption.33}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces The figure represents distribution for Section 2 of survey. The participants were asked to rate the image based on photorealism(1 being the least photorealistic). \gls {free} has maximum number of least rating(1), but it is comparable to other automated datasets as highlighted. Pix3D has maximum number of highest rating(10).\relax }}{40}{figure.caption.34}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces The figure represents average rating given by the participant to each of the datasets in section 2 of the survey. The automated datasets are highlighted, all of them have lower average. \gls {ai2thor}(Unity based and manually designed) is also among the lower averages.\relax }}{40}{figure.caption.35}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces The figure represents distribution for Section 3 of survey. The participants were asked to rank the images based on photorealism(1 being the best) by comparing images from all 9 datasets. The automated datasets are highlighted. \gls {free} dataset appears in top 5 maximum number of times, seen to the left of the dotted line.\relax }}{41}{figure.caption.36}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces The figure represents box plot for section 3. The orange horizontal line within the box indicates median, the blue dotted line indicates mean. The bolder boxes represents automated dataset, while lighter boxes represent manually created dataset. \Gls {free} has highest mean among the automated datasets.\relax }}{41}{figure.caption.37}%
\contentsline {figure}{\numberline {5.6}{\ignorespaces T-SNE visualisation for images from various photo-realistic synthetic dataset. Pix3d and \gls {free} are highlighted with bolder colors. Both these datasets have wide spread in the embedding space.\relax }}{43}{figure.caption.38}%
\contentsline {figure}{\numberline {5.7}{\ignorespaces T-SNE visualisation for images from Pix3d and \gls {free} dataset.We observe that \gls {free} still doesnt encapsulate the embedding space like Pix3D.\relax }}{44}{figure.caption.39}%
\contentsline {figure}{\numberline {5.8}{\ignorespaces T-SNE visualisation for images from individual photo-realistic synthetic dataset compared with Pix3D latent space. (Left to right, top to bottom) Openrooms, SceneNet, Blenderproc, \gls {ai2thor}, \gls {front}, Hyperism, \gls {free} in blue; compared with Pix3D in orange.\relax }}{45}{figure.caption.40}%
\contentsline {figure}{\numberline {5.9}{\ignorespaces T-SNE visualisation for images from individual synthetic chair dataset with different domain randomisation parameter compared with Pix3D chair latent space. (Left to right, top to bottom) Textureless, Textureless with light, Textured, Textured with light, Multi-Object\relax }}{47}{figure.caption.42}%
\contentsline {figure}{\numberline {5.10}{\ignorespaces A combined T-SNE visualisation for chair images from Pix3d and \gls {free} dataset with different parameters for randomisation.\relax }}{48}{figure.caption.43}%
\contentsline {figure}{\numberline {5.11}{\ignorespaces Samples of images from real and synthetic datasets.\relax }}{49}{figure.caption.44}%
\contentsline {figure}{\numberline {5.12}{\ignorespaces Samples of images used for ablation study on chairs with different parameters of domain randomisation.\relax }}{49}{figure.caption.45}%
\contentsline {figure}{\numberline {5.13}{\ignorespaces Line plot for the \gls {iou} for baselines trained on real and synthetic datasets, with and without 2D augmentation. (Left)The checkpoint was saved using real dataset for validation and test, (right) the checkpoint was saved using corresponding synthetic data for validation step and tested with real data. In both the cases we see that ~\gls {free} does not perform adequately on its own. \gls {s2rv2} contributes better than \gls {s2rv1}.\relax }}{50}{figure.caption.46}%
\contentsline {figure}{\numberline {5.14}{\ignorespaces Line plot for the \gls {iou} for baseline models(Pix2Vox++ and Pix2Vox) trained on synthetic and fine-tuned with real dataset. We see that even after fine-tuning both the models do not perform as good as models trained on only real dataset.\relax }}{51}{figure.caption.47}%
\contentsline {figure}{\numberline {5.15}{\ignorespaces Parallel coordinate plot for the \gls {iou} for baseline pix2vox++ trained on (\gls {s2rv1}, \gls {s2rv2}) and fine-tuned with pix3d. The categories are listed along with the number of images. The performance of {pix2vox++} mixed with both the synthetic dataset is less than model trained on only pix3d, for majority of the categories.\relax }}{52}{figure.caption.48}%
\contentsline {figure}{\numberline {5.16}{\ignorespaces Parallel coordinate plot for the \gls {iou} for baseline {pix2vox} trained on (\gls {s2rv1}, \gls {s2rv2}) and fine-tuned with pix3d. The categories are listed along with the number of images. The performance of pix2vox mixed with both the synthetic dataset is less than model trained on only pix3d, for majority the categories.\relax }}{52}{figure.caption.49}%
\contentsline {figure}{\numberline {5.17}{\ignorespaces Line plot for the \gls {iou} for baselines trained on different ratios of synthetic and real dataset. (Left)Mixed training on Pix2Vox++, (right)Mixed training on Pix2Vox. In both cases we see a slight increase in \gls {iou} with addition of real data, and a gradual decrease till it reaches 100\% real data\relax }}{53}{figure.caption.50}%
\contentsline {figure}{\numberline {5.18}{\ignorespaces Parallel coordinate plot for the \gls {iou} for baseline {pix2vox++} trained on 50\% of mixed dataset(\gls {s2rv1}, \gls {s2rv2}) and with pix3d. The categories are listed along with the number of images. The performance of pix2vox++ mixed with both the synthetic dataset is more than model trained on only pix3d, for most of the categories. \relax }}{54}{figure.caption.51}%
\contentsline {figure}{\numberline {5.19}{\ignorespaces Parallel coordinate plot for the \gls {iou} for baseline {pix2vox} trained on 50\% of mixed dataset(\gls {s2rv1}, \gls {s2rv2}) and with pix3d. The categories are listed along with the number of images. The performance of pix2vox mixed with both the synthetic dataset is more than model trained on only pix3d, for all the categories.\relax }}{54}{figure.caption.52}%
\contentsline {figure}{\numberline {5.20}{\ignorespaces Line plot for the \gls {iou} for baseline trained on chair dataset with different domain randomization parameters and tested on real dataset. We see a dip in performance near textureless dataset, but it gradually increases with addition of domain randomization parameter.\relax }}{55}{figure.caption.53}%
\contentsline {figure}{\numberline {5.21}{\ignorespaces Line plot for the \gls {iou} for baseline trained by mixing chair dataset from real and synthetic dataset with ratio of 50\%. Observe that the {IoU} is consistent for all types of randomization proving that mixed training negates loss from randomization.]\relax }}{56}{figure.caption.54}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {A.1}{\ignorespaces Line plot for the \gls {f1} for baselines trained on real and synthetic datasets, with and without 2D augmentation. We see that ~\gls {free} does not perform adequately on its own. \gls {s2rv2} contributes slightly better than \gls {s2rv1}.\relax }}{62}{figure.caption.56}%
\contentsline {figure}{\numberline {A.2}{\ignorespaces Line plot for the \gls {f1} for baseline models(Pix2Vox++ and Pix2Vox) trained on synthetic and fine-tuned with real dataset. We see that even after fine-tuning both the models do not perform as good as models trained on only real dataset.\relax }}{62}{figure.caption.57}%
\contentsline {figure}{\numberline {A.3}{\ignorespaces Parallel coordinate plot for the \gls {f1} for baseline pix2vox++ trained on (\gls {s2rv1}, \gls {s2rv2}) and fine-tuned with pix3d. The categories are listed along with the number of images. The performance of {pix2vox++} mixed with both the synthetic dataset is less than model trained on only pix3d, for majority of the categories.\relax }}{63}{figure.caption.58}%
\contentsline {figure}{\numberline {A.4}{\ignorespaces Parallel coordinate plot for the \gls {f1} for baseline {pix2vox} trained on (\gls {s2rv1}, \gls {s2rv2}) and fine-tuned with pix3d. The categories are listed along with the number of images. The performance of pix2vox mixed with both the synthetic dataset is less than model trained on only pix3d, for majority the categories.\relax }}{63}{figure.caption.59}%
\contentsline {figure}{\numberline {A.5}{\ignorespaces Line plot for the \gls {f1} for baselines trained on different ratios of synthetic and real dataset. (Left)Mixed training on Pix2Vox++, (right)Mixed training on Pix2Vox. In both cases we see a slight increase in \gls {f1} with addition of real data, and a gradual decrease till it reaches 100\% real data\relax }}{64}{figure.caption.60}%
\contentsline {figure}{\numberline {A.6}{\ignorespaces Parallel coordinate plot for the \gls {f1} for baseline {pix2vox++} trained on 50\% of mixed dataset(\gls {s2rv1}, \gls {s2rv2}) and with pix3d. The categories are listed along with the number of images. The performance of pix2vox++ mixed with both the synthetic dataset is more than model trained on only pix3d, for most of the categories. \relax }}{64}{figure.caption.61}%
\contentsline {figure}{\numberline {A.7}{\ignorespaces Parallel coordinate plot for the \gls {f1} for baseline {pix2vox} trained on 50\% of mixed dataset(\gls {s2rv1}, \gls {s2rv2}) and with pix3d. The categories are listed along with the number of images. The performance of pix2vox mixed with both the synthetic dataset is more than model trained on only pix3d, for all the categories.\relax }}{65}{figure.caption.62}%
\contentsline {figure}{\numberline {A.8}{\ignorespaces Line plot for the \gls {f1} for baseline trained on chair dataset with different domain randomization parameters and tested on real dataset. We see a dip in performance near textureless dataset, but it gradually increases with addition of domain randomization parameter.\relax }}{66}{figure.caption.63}%
\contentsline {figure}{\numberline {A.9}{\ignorespaces Line plot for the \gls {f1} for baseline trained by mixing chair dataset from real and synthetic dataset with ratio of 50\%. Observe that the {IoU} is consistent for all types of randomization proving that mixed training negates loss from randomization.\relax }}{66}{figure.caption.64}%
\contentsline {figure}{\numberline {A.10}{\ignorespaces Sample images for models rendered in High Definition Render Pipeline of Unity\relax }}{67}{figure.caption.65}%
\contentsline {figure}{\numberline {A.11}{\ignorespaces A sample question used for survey section 1. For section 1, participants were asked to select 'Real' or 'Not real' for 27 images, 3 images per dataset.\relax }}{68}{figure.caption.66}%
\contentsline {figure}{\numberline {A.12}{\ignorespaces A sample question used for survey section 2. For section 2, participants were asked rate the 27 images from 1 to 10. We had 3 images per dataset.\relax }}{68}{figure.caption.67}%
\contentsline {figure}{\numberline {A.13}{\ignorespaces A sample question used for survey section 3. For section 3, the users were shown 9 images together and asked to rank them on descending order of photorealism. \relax }}{69}{figure.caption.68}%
