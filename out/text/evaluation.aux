\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{Fu20203DFRONT3F}
\citation{Roberts2020HypersimAP}
\citation{InteriorNet18}
\citation{McCormac2017}
\citation{dlr139317}
\citation{ai2thor}
\citation{Li_2021_CVPR}
\citation{Sun2018}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Experiments and Evaluation}{45}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:evaluation}{{5}{45}{\iftoggle {german}{Evaluierung}{Experiments and Evaluation}}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}A survey on photorealism}{45}{section.5.1}\protected@file@percent }
\newlabel{sec:a-survey-on-photorealism}{{5.1}{45}{A survey on photorealism}{section.5.1}{}}
\@writefile{brf}{\backcite{Fu20203DFRONT3F}{{45}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{Roberts2020HypersimAP}{{45}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{InteriorNet18}{{45}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{McCormac2017}{{45}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{dlr139317}{{45}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{ai2thor}{{45}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{Li_2021_CVPR}{{45}{5.1}{section.5.1}}}
\@writefile{brf}{\backcite{Sun2018}{{45}{5.1}{section.5.1}}}
\citation{Sun2018}
\citation{Roberts2020HypersimAP}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Section 1: Real or Not}{46}{subsection.5.1.1}\protected@file@percent }
\@writefile{brf}{\backcite{Sun2018}{{46}{5.1.1}{subsection.5.1.1}}}
\@writefile{brf}{\backcite{Roberts2020HypersimAP}{{46}{5.1.1}{subsection.5.1.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Section 2: Likert Scale}{46}{subsection.5.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces The figure represents distribution for Section 1 of survey. The participants were asked to distinguish if the image was 'Real' or 'Nor Real'. The automated dataset is highlighted with bolder color. The dotted line is 50\% threshold. All the automated dataset have less than threshold votes for 'Real'.\relax }}{47}{figure.caption.33}\protected@file@percent }
\newlabel{fig:question1}{{5.1}{47}{The figure represents distribution for Section 1 of survey. The participants were asked to distinguish if the image was 'Real' or 'Nor Real'. The automated dataset is highlighted with bolder color. The dotted line is 50\% threshold. All the automated dataset have less than threshold votes for 'Real'.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Section 3: Rank by comparison}{47}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Summary for survey}{47}{subsection.5.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces The figure represents distribution for Section 2 of survey. The participants were asked to rate the image based on photorealism(1 being the least photorealistic). \gls {free} has maximum number of least rating(1), but it is comparable to other automated datasets as highlighted. Pix3D has maximum number of highest rating(10).\relax }}{48}{figure.caption.34}\protected@file@percent }
\newlabel{fig:question2}{{5.2}{48}{The figure represents distribution for Section 2 of survey. The participants were asked to rate the image based on photorealism(1 being the least photorealistic). \gls {free} has maximum number of least rating(1), but it is comparable to other automated datasets as highlighted. Pix3D has maximum number of highest rating(10).\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces The figure represents average rating given by the participant to each of the datasets in section 2 of the survey. The automated datasets are highlighted, all of them have lower average. \gls {ai2thor}(Unity based and manually designed) is also among the lower averages.\relax }}{48}{figure.caption.35}\protected@file@percent }
\newlabel{fig:question2_2}{{5.3}{48}{The figure represents average rating given by the participant to each of the datasets in section 2 of the survey. The automated datasets are highlighted, all of them have lower average. \gls {ai2thor}(Unity based and manually designed) is also among the lower averages.\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces The figure represents distribution for Section 3 of survey. The participants were asked to rank the images based on photorealism(1 being the best) by comparing images from all 9 datasets. The automated datasets are highlighted. \gls {free} dataset appears in top 5 maximum number of times, seen to the left of the dotted line.\relax }}{49}{figure.caption.36}\protected@file@percent }
\newlabel{fig:question3}{{5.4}{49}{The figure represents distribution for Section 3 of survey. The participants were asked to rank the images based on photorealism(1 being the best) by comparing images from all 9 datasets. The automated datasets are highlighted. \gls {free} dataset appears in top 5 maximum number of times, seen to the left of the dotted line.\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces The figure represents box plot for section 3. The orange horizontal line within the box indicates median, the blue dotted line indicates mean. The bolder boxes represents automated dataset, while lighter boxes represent manually created dataset. \Gls {free} has highest mean among the automated datasets.\relax }}{49}{figure.caption.37}\protected@file@percent }
\newlabel{fig:question3_2}{{5.5}{49}{The figure represents box plot for section 3. The orange horizontal line within the box indicates median, the blue dotted line indicates mean. The bolder boxes represents automated dataset, while lighter boxes represent manually created dataset. \Gls {free} has highest mean among the automated datasets.\relax }{figure.caption.37}{}}
\citation{simonyan2015deep}
\citation{Deng2009ImageNetAL}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Domain gaps}{50}{section.5.2}\protected@file@percent }
\newlabel{sec:domain-gaps}{{5.2}{50}{Domain gaps}{section.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Qualitative}{50}{subsection.5.2.1}\protected@file@percent }
\newlabel{subsec:qualitative}{{5.2.1}{50}{Qualitative}{subsection.5.2.1}{}}
\@writefile{brf}{\backcite{simonyan2015deep}{{50}{5.2.1}{subsection.5.2.1}}}
\@writefile{brf}{\backcite{Deng2009ImageNetAL}{{50}{5.2.1}{subsection.5.2.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces \gls {tsne} visualization for images from various photo-realistic synthetic dataset. Pix3D and \gls {free} are highlighted with bolder colors. Both these datasets have wide spread in the embedding space.\relax }}{50}{figure.caption.38}\protected@file@percent }
\newlabel{fig:photorealistic tsne}{{5.6}{50}{\gls {tsne} visualization for images from various photo-realistic synthetic dataset. Pix3D and \gls {free} are highlighted with bolder colors. Both these datasets have wide spread in the embedding space.\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces \gls {tsne} visualization for images from individual photo-realistic synthetic dataset compared with Pix3D latent space. (Left to right, top to bottom) Openrooms, SceneNet, Blenderproc, \gls {ai2thor}, \gls {front}, Hyperism, InteriorNet, \gls {free} in blue; compared with Pix3D in orange.\relax }}{51}{figure.caption.39}\protected@file@percent }
\newlabel{fig:tsne per dataset}{{5.7}{51}{\gls {tsne} visualization for images from individual photo-realistic synthetic dataset compared with Pix3D latent space. (Left to right, top to bottom) Openrooms, SceneNet, Blenderproc, \gls {ai2thor}, \gls {front}, Hyperism, InteriorNet, \gls {free} in blue; compared with Pix3D in orange.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces \gls {tsne} visualization for images from Pix3D and \gls {free} dataset.We observe that \gls {free} still doesnt encapsulate the embedding space like Pix3D.\relax }}{52}{figure.caption.40}\protected@file@percent }
\newlabel{fig:pix3d_s2r3dfree}{{5.8}{52}{\gls {tsne} visualization for images from Pix3D and \gls {free} dataset.We observe that \gls {free} still doesnt encapsulate the embedding space like Pix3D.\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Quantitative}{53}{subsection.5.2.2}\protected@file@percent }
\newlabel{subsec:quantitative}{{5.2.2}{53}{Quantitative}{subsection.5.2.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Table represents quantitative - \gls {fid} measure to compare synthetic dataset distribution with the real dataset(Pix3D). InteriorNet has the least \gls {fid} and hence the most similarity to real dataset distribution.\relax }}{53}{table.caption.41}\protected@file@percent }
\newlabel{tab:quantitative-dataset-comparison}{{5.1}{53}{Table represents quantitative - \gls {fid} measure to compare synthetic dataset distribution with the real dataset(Pix3D). InteriorNet has the least \gls {fid} and hence the most similarity to real dataset distribution.\relax }{table.caption.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Domain gap for \gls {free} ablation datasets}{53}{subsection.5.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces \gls {tsne} visualization for images from individual synthetic chair dataset with different domain randomization parameter compared with Pix3D chair latent space. (Left to right, top to bottom) Textureless, Textureless with light, Textured, Textured with light, Multi-Object and Combined.\relax }}{54}{figure.caption.42}\protected@file@percent }
\newlabel{fig:tsne per chair dataset}{{5.9}{54}{\gls {tsne} visualization for images from individual synthetic chair dataset with different domain randomization parameter compared with Pix3D chair latent space. (Left to right, top to bottom) Textureless, Textureless with light, Textured, Textured with light, Multi-Object and Combined.\relax }{figure.caption.42}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Table represents quantitative - \gls {fid} measure to compare chair synthetic dataset distribution with the real dataset(Pix3D). Multi-Object dataset has the least \gls {fid} and hence is most similar to real dataset.\relax }}{55}{table.caption.43}\protected@file@percent }
\newlabel{tab:quantitative-dataset-comparison-chair-dataset}{{5.2}{55}{Table represents quantitative - \gls {fid} measure to compare chair synthetic dataset distribution with the real dataset(Pix3D). Multi-Object dataset has the least \gls {fid} and hence is most similar to real dataset.\relax }{table.caption.43}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Baseline}{55}{section.5.3}\protected@file@percent }
\newlabel{sec:baseline}{{5.3}{55}{Baseline}{section.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Bar plot for the \gls {iou} for \textbf  {baselines} trained on real and synthetic datasets, with and without 2D augmentation. (a)The checkpoint was saved using real dataset for validation and test, (b) The checkpoint was saved using corresponding synthetic data for validation step and tested with real data. In both the cases we see that ~\gls {free} does not perform adequately on its own. \gls {s2rv2} contributes better than \gls {s2rv1}.\relax }}{56}{figure.caption.44}\protected@file@percent }
\newlabel{fig:baseline1}{{5.10}{56}{Bar plot for the \gls {iou} for \textbf {baselines} trained on real and synthetic datasets, with and without 2D augmentation. (a)The checkpoint was saved using real dataset for validation and test, (b) The checkpoint was saved using corresponding synthetic data for validation step and tested with real data. In both the cases we see that ~\gls {free} does not perform adequately on its own. \gls {s2rv2} contributes better than \gls {s2rv1}.\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces 3D reconstruction outputs for models trained on \textbf  {only real dataset}, and \textbf  {only synthetic dataset}. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D(real dataset). Output3-4: Pix2Vox++ and Pix2Vox trained with only \gls {s2rv2} synthetic dataset. This corresponds to the bad \gls {iou} when trained on only synthetic dataset.\relax }}{57}{figure.caption.45}\protected@file@percent }
\newlabel{fig:baseline_images1}{{5.11}{57}{3D reconstruction outputs for models trained on \textbf {only real dataset}, and \textbf {only synthetic dataset}. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D(real dataset). Output3-4: Pix2Vox++ and Pix2Vox trained with only \gls {s2rv2} synthetic dataset. This corresponds to the bad \gls {iou} when trained on only synthetic dataset.\relax }{figure.caption.45}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Fine Tuning}{57}{section.5.4}\protected@file@percent }
\newlabel{sec:fine-tuning}{{5.4}{57}{Fine Tuning}{section.5.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Bar plot for the \gls {iou} for baseline models(Pix2Vox++ and Pix2Vox) trained on synthetic and \textbf  {fine-tuned} with real dataset. We see that even after fine-tuning both the models do not perform as good as models trained on only real dataset.\relax }}{58}{figure.caption.46}\protected@file@percent }
\newlabel{fig:finetuning1}{{5.12}{58}{Bar plot for the \gls {iou} for baseline models(Pix2Vox++ and Pix2Vox) trained on synthetic and \textbf {fine-tuned} with real dataset. We see that even after fine-tuning both the models do not perform as good as models trained on only real dataset.\relax }{figure.caption.46}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Mixed Training}{58}{section.5.5}\protected@file@percent }
\newlabel{sec:mixed-training}{{5.5}{58}{Mixed Training}{section.5.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Bar plot for the \gls {iou} for baseline {Pix2Vox++} trained on (\gls {s2rv1}, \gls {s2rv2}) and \textbf  {fine-tuned} with Pix3D. The categories are listed along with the number of images. The performance of {Pix2Vox++} mixed with both the synthetic dataset is less than model trained on only Pix3D, for majority of the categories.\relax }}{59}{figure.caption.47}\protected@file@percent }
\newlabel{fig:finetuning2}{{5.13}{59}{Bar plot for the \gls {iou} for baseline \texbf {Pix2Vox++} trained on (\gls {s2rv1}, \gls {s2rv2}) and \textbf {fine-tuned} with Pix3D. The categories are listed along with the number of images. The performance of \texbf {Pix2Vox++} mixed with both the synthetic dataset is less than model trained on only Pix3D, for majority of the categories.\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Bar plot for the \gls {iou} for baseline {Pix2Vox} trained on (\gls {s2rv1}, \gls {s2rv2}) and {fine-tuned} with Pix3D. The categories are listed along with the number of images. The performance of \textbf  {Pix2Vox} mixed with both the synthetic dataset is less than model trained on only Pix3D, for majority the categories.\relax }}{59}{figure.caption.48}\protected@file@percent }
\newlabel{fig:finetuning3}{{5.14}{59}{Bar plot for the \gls {iou} for baseline \texbf {Pix2Vox} trained on (\gls {s2rv1}, \gls {s2rv2}) and \texbf {fine-tuned} with Pix3D. The categories are listed along with the number of images. The performance of \textbf {Pix2Vox} mixed with both the synthetic dataset is less than model trained on only Pix3D, for majority the categories.\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces 3D reconstruction outputs for models trained on real dataset and synthetic datasets with \textbf  {fine-tuning}. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D(real dataset). Output3-4: Pix2Vox++ and Pix2Vox pre-trained with only \gls {s2rv2} synthetic dataset and then fine-tuned with Pix3D. The reconstruction is better than models trained on only synthetic dataset.\relax }}{60}{figure.caption.49}\protected@file@percent }
\newlabel{fig:finetuning_images1}{{5.15}{60}{3D reconstruction outputs for models trained on real dataset and synthetic datasets with \textbf {fine-tuning}. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D(real dataset). Output3-4: Pix2Vox++ and Pix2Vox pre-trained with only \gls {s2rv2} synthetic dataset and then fine-tuned with Pix3D. The reconstruction is better than models trained on only synthetic dataset.\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Bar plot for the \gls {iou} for baselines trained on different ratios of synthetic and real dataset per mini-batch.(a)\textbf  {Mixed training on Pix2Vox++}, (b)\textbf  {Mixed training on Pix2Vox}. In both cases we see a slight increase in \gls {iou} with addition of real data, and a gradual decrease till it reaches 100\% real data\relax }}{61}{figure.caption.50}\protected@file@percent }
\newlabel{fig:mixed1}{{5.16}{61}{Bar plot for the \gls {iou} for baselines trained on different ratios of synthetic and real dataset per mini-batch.(a)\textbf {Mixed training on Pix2Vox++}, (b)\textbf {Mixed training on Pix2Vox}. In both cases we see a slight increase in \gls {iou} with addition of real data, and a gradual decrease till it reaches 100\% real data\relax }{figure.caption.50}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Bar plot for the \gls {iou} for baseline {Pix2Vox++} trained on 50\% of \textbf  {mixed dataset}(\gls {s2rv1}, \gls {s2rv2}) and with Pix3D. The categories are listed along with the number of images. The performance of Pix2Vox++ mixed with both the synthetic dataset is more than model trained on only Pix3D, for majority of the categories. \relax }}{62}{figure.caption.51}\protected@file@percent }
\newlabel{fig:mixed2}{{5.17}{62}{Bar plot for the \gls {iou} for baseline \texbf {Pix2Vox++} trained on 50\% of \textbf {mixed dataset}(\gls {s2rv1}, \gls {s2rv2}) and with Pix3D. The categories are listed along with the number of images. The performance of Pix2Vox++ mixed with both the synthetic dataset is more than model trained on only Pix3D, for majority of the categories. \relax }{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.18}{\ignorespaces Bar plot for the \gls {iou} for baseline {Pix2Vox} trained on 50\% of \textbf  {mixed dataset}(\gls {s2rv1}, \gls {s2rv2}) and with Pix3D. The categories are listed along with the number of images. The performance of Pix2Vox mixed with both the synthetic dataset is more than model trained on only Pix3D, for all the categories.\relax }}{62}{figure.caption.52}\protected@file@percent }
\newlabel{fig:mixed3}{{5.18}{62}{Bar plot for the \gls {iou} for baseline \texbf {Pix2Vox} trained on 50\% of \textbf {mixed dataset}(\gls {s2rv1}, \gls {s2rv2}) and with Pix3D. The categories are listed along with the number of images. The performance of Pix2Vox mixed with both the synthetic dataset is more than model trained on only Pix3D, for all the categories.\relax }{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.19}{\ignorespaces 3D reconstruction outputs for best \textbf  {mixed training}(50\% per mini-batch) models. Output1-2: Pix2Vox++ and Pix2Vox mixed trained with \gls {s2rv1}. Output3-4:Pix2Vox++ and Pix2Vox mixed trained with \gls {s2rv2}\relax }}{63}{figure.caption.53}\protected@file@percent }
\newlabel{fig:mixed_images1}{{5.19}{63}{3D reconstruction outputs for best \textbf {mixed training}(50\% per mini-batch) models. Output1-2: Pix2Vox++ and Pix2Vox mixed trained with \gls {s2rv1}. Output3-4:Pix2Vox++ and Pix2Vox mixed trained with \gls {s2rv2}\relax }{figure.caption.53}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Ablation study on chairs}{64}{section.5.6}\protected@file@percent }
\newlabel{sec:ablation-study-on-chairs}{{5.6}{64}{Ablation study on chairs}{section.5.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.1}Domain randomization on chair dataset}{64}{subsection.5.6.1}\protected@file@percent }
\newlabel{subsec:domain-randomisation-on-chair-dataset}{{5.6.1}{64}{Domain randomization on chair dataset}{subsection.5.6.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.20}{\ignorespaces Bar plot for the \gls {iou} for \textbf  {baseline} trained on chair dataset with different domain randomization parameters and tested on real dataset. We see a dip in performance near textureless dataset, but it gradually increases with addition of domain randomization parameter.\relax }}{64}{figure.caption.54}\protected@file@percent }
\newlabel{fig:ablation1}{{5.20}{64}{Bar plot for the \gls {iou} for \textbf {baseline} trained on chair dataset with different domain randomization parameters and tested on real dataset. We see a dip in performance near textureless dataset, but it gradually increases with addition of domain randomization parameter.\relax }{figure.caption.54}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.2}Domain randomization with Mixed training}{65}{subsection.5.6.2}\protected@file@percent }
\newlabel{subsec:domain-randomisation-with-mixed-training}{{5.6.2}{65}{Domain randomization with Mixed training}{subsection.5.6.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Discussion}{65}{section.5.7}\protected@file@percent }
\newlabel{subsec:discussion}{{5.7}{65}{Discussion}{section.5.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.21}{\ignorespaces 3D reconstruction outputs for best \textbf  {ablation} models and models trained on only synthetic dataset. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D. Output3-4: Pix2Vox++ and Pix2Vox trained on Multi-object chair synthetic dataset, reconstructs a generic chair with less detail.\relax }}{66}{figure.caption.55}\protected@file@percent }
\newlabel{fig:ablation_images1}{{5.21}{66}{3D reconstruction outputs for best \textbf {ablation} models and models trained on only synthetic dataset. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D. Output3-4: Pix2Vox++ and Pix2Vox trained on Multi-object chair synthetic dataset, reconstructs a generic chair with less detail.\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.22}{\ignorespaces Bar plot for the \gls {iou} for baseline trained by \textbf  {mixing} chair dataset from real and synthetic dataset with ratio of 50\%. Observe that the {IoU} is consistent for all types of randomization proving that mixed training negates loss from randomization.]\relax }}{67}{figure.caption.56}\protected@file@percent }
\newlabel{fig:ablation2}{{5.22}{67}{Bar plot for the \gls {iou} for baseline trained by \textbf {mixing} chair dataset from real and synthetic dataset with ratio of 50\%. Observe that the \fls {IoU} is consistent for all types of randomization proving that mixed training negates loss from randomization.]\relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.23}{\ignorespaces 3D reconstruction outputs for best ablation models and models with \textbf  {mixed} training. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D. Output3-4:Pix2Vox++ and Pix2Vox trained with mixed ratio of 50\% with multi-object chair synthetic dataset, reconstructs chair with more details.\relax }}{68}{figure.caption.57}\protected@file@percent }
\newlabel{fig:mixed_ablation_images2}{{5.23}{68}{3D reconstruction outputs for best ablation models and models with \textbf {mixed} training. Output1-2: Pix2Vox++ and Pix2Vox trained on Pix3D. Output3-4:Pix2Vox++ and Pix2Vox trained with mixed ratio of 50\% with multi-object chair synthetic dataset, reconstructs chair with more details.\relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.24}{\ignorespaces A sample output where more than one furniture seem to be predicted. (left) Input image, (center) Ground truth, (right) Predicted output. The model seems to predict both the chair and the table with the context it learnt during training.\relax }}{69}{figure.caption.58}\protected@file@percent }
\newlabel{fig:interesting1}{{5.24}{69}{A sample output where more than one furniture seem to be predicted. (left) Input image, (center) Ground truth, (right) Predicted output. The model seems to predict both the chair and the table with the context it learnt during training.\relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.25}{\ignorespaces A sample output where a more focused furniture is getting predicted instead of ground truth. (left) Input image, (center) Ground truth, (right) Predicted output. The model seems to predict the chair instead of the table. \relax }}{69}{figure.caption.59}\protected@file@percent }
\newlabel{fig:interesting2}{{5.25}{69}{A sample output where a more focused furniture is getting predicted instead of ground truth. (left) Input image, (center) Ground truth, (right) Predicted output. The model seems to predict the chair instead of the table. \relax }{figure.caption.59}{}}
\@setckpt{text/evaluation}{
\setcounter{page}{70}
\setcounter{equation}{0}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{13}
\setcounter{mpfootnote}{0}
\setcounter{nag@c}{51}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{7}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{25}
\setcounter{table}{2}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{2}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{lotdepth}{1}
\setcounter{NAT@ctr}{0}
\setcounter{parentequation}{0}
\setcounter{tcbbreakpart}{0}
\setcounter{tcblayer}{0}
\setcounter{tcolorbox@number}{0}
\setcounter{mn@abspage}{92}
\setcounter{lstnumber}{1}
\setcounter{float@type}{16}
\setcounter{nlinenum}{0}
\setcounter{su@anzahl}{0}
\setcounter{DTLrowi}{0}
\setcounter{DTLrowii}{0}
\setcounter{DTLrowiii}{0}
\setcounter{DTLrow}{0}
\setcounter{Item}{24}
\setcounter{Hfootnote}{13}
\setcounter{bookmark@seq@number}{84}
\setcounter{LT@tables}{1}
\setcounter{LT@chunks}{1}
\setcounter{tcb@cnt@definition}{0}
\setcounter{tcb@cnt@theorem}{0}
\setcounter{lstlisting}{0}
\setcounter{section@level}{1}
}
